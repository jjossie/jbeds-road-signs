{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOqnzDjHmYl5AncVBMsAxz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjossie/jbeds-road-signs/blob/main/Erik_GANs_Inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHZl_JiuJT1H",
        "outputId": "e15cfb04-b149-477d-913d-7de357504e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files...\n",
            "Unzipping files...\n",
            "Merging training data...\n",
            "Cleaning up...\n",
            "Data ready.\n"
          ]
        }
      ],
      "source": [
        "# Note: After you run this cell, the training and test data will be available in\n",
        "# the file browser. (Click the folder icon on the left to view it)\n",
        "#\n",
        "# If you don't see the data after the cell completes, click the refresh button\n",
        "# in the file browser (folder icon with circular arrow)\n",
        "\n",
        "# First, let's download and unzip the data\n",
        "!echo \"Downloading files...\"\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training1.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training2.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test_partial.zip\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test_classes_partial.csv\n",
        "\n",
        "!echo \"Unzipping files...\"\n",
        "!unzip -q /content/training1.zip\n",
        "!unzip -q /content/training2.zip\n",
        "!unzip -q /content/test.zip\n",
        "!unzip -q /content/test_partial.zip\n",
        "\n",
        "# Combine the two traning directories\n",
        "!echo \"Merging training data...\"\n",
        "!mkdir /content/training\n",
        "!mv /content/training1/* /content/training\n",
        "!mv /content/training2/* /content/training\n",
        "\n",
        "# Cleanup\n",
        "!echo \"Cleaning up...\"\n",
        "!rmdir /content/training1\n",
        "!rmdir /content/training2\n",
        "!rm training1.zip\n",
        "!rm training2.zip\n",
        "!rm test.zip\n",
        "!rm test_partial.zip\n",
        "\n",
        "!echo \"Data ready.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications import InceptionV3\n",
        "from keras.applications import VGG16\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "JI-9lYIaJdVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a function to add random noise to an image\n",
        "def add_random_noise(image):\n",
        "    noise = np.random.normal(loc=0, scale=0.1, size=image.shape)  # Gaussian noise with mean 0 and standard deviation 0.1\n",
        "    noisy_image = image + noise\n",
        "    return np.clip(noisy_image, 0, 1)  # Clip values to ensure they are within the valid range [0, 1]\n"
      ],
      "metadata": {
        "id": "Fkz4pAy1NrCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We're using keras' ImageDataGenerator class to load our image data.\n",
        "# See (https://keras.io/api/preprocessing/image/#imagedatagenerator-class) for details\n",
        "#\n",
        "# A couple of things to note:\n",
        "# 1. We're specifying a number for the seed, so we'll always get the same shuffle and split of our images.\n",
        "# 2. Class names are inferred automatically from the image subdirectory names.\n",
        "# 3. We're splitting the training data into 80% training, 20% validation.\n",
        "\n",
        "\n",
        "training_dir = '/content/training/'\n",
        "image_size = (224, 224)\n",
        "\n",
        "# Split up the training data images into training and validations sets\n",
        "# We'll use and ImageDataGenerator to do the splits\n",
        "# ImageDataGenerator can also be used to do preprocessing and agumentation on the files as can be seen with rescale\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,  # Random rotation within ±20 degrees\n",
        "        zoom_range=0.2,     # Random zooming within ±20%\n",
        "        width_shift_range=0.2,  # Random horizontal shifting\n",
        "        height_shift_range=0.2, # Random vertical shifting\n",
        "        preprocessing_function=add_random_noise,  # Add Gaussian noise\n",
        "        validation_split=.2\n",
        "        )\n",
        "validation_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        # rotation_range=20,  # Random rotation within ±20 degrees\n",
        "        # zoom_range=0.2,     # Random zooming within ±20%\n",
        "        # width_shift_range=0.2,  # Random horizontal shifting\n",
        "        # height_shift_range=0.2, # Random vertical shifting\n",
        "        # preprocessing_function=add_random_noise,  # Add Gaussian noise\n",
        "        validation_split=.2\n",
        "        )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        training_dir,\n",
        "        target_size = image_size,\n",
        "        subset=\"training\",\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        seed=42,shuffle=True)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        training_dir,\n",
        "        target_size=image_size,\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset=\"validation\",\n",
        "        seed=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCTTQmR8JdS7",
        "outputId": "9df8e4f9-b5ea-44a4-c112-9d3f2f2b6966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31368 images belonging to 43 classes.\n",
            "Found 7841 images belonging to 43 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # GAN\n",
        "\n",
        "# # Create the generator model\n",
        "# generator_model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Dense(256 * 7 * 7, activation='relu', input_dim=100),\n",
        "#     tf.keras.layers.Reshape((7, 7, 256)),\n",
        "#     tf.keras.layers.Conv2DTranspose(128, kernel_size=5, strides=2, padding='same', activation='relu'),\n",
        "#     tf.keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding='same', activation='relu'),\n",
        "#     tf.keras.layers.Conv2DTranspose(32, kernel_size=5, strides=2, padding='same', activation='relu'),\n",
        "#     tf.keras.layers.Conv2DTranspose(3, kernel_size=5, strides=2, padding='same', activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# # Create the discriminator model\n",
        "# discriminator_model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Conv2D(32, kernel_size=5, strides=2, padding='same', activation='relu', input_shape=(7, 7, 256)),\n",
        "#     tf.keras.layers.Conv2D(64, kernel_size=5, strides=2, padding='same', activation='relu'),\n",
        "#     tf.keras.layers.Conv2D(128, kernel_size=5, strides=2, padding='same', activation='relu'),\n",
        "#     tf.keras.layers.Conv2D(256, kernel_size=5, strides=2, padding='same', activation='relu'),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# # Create the combined GAN model\n",
        "# combined_model = tf.keras.Sequential([\n",
        "#     generator_model,\n",
        "#     discriminator_model\n",
        "# ])\n",
        "\n",
        "# # Compile the discriminator model\n",
        "# discriminator_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Compile the combined GAN model\n",
        "# combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the discriminator and generator iteratively\n",
        "# for epoch in range(5):\n",
        "#     # Train the discriminator\n",
        "#     discriminator_model.fit(train_generator, epochs=1)\n",
        "\n",
        "#     # Train the generator (while keeping the discriminator weights fixed)\n",
        "#     combined_model.layers[0].trainable = True  # Enable training for the generator\n",
        "#     combined_model.layers[1].trainable = False  # Disable training for the discriminator\n",
        "#     combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#     combined_model.fit(train_generator, epochs=1)\n",
        "\n",
        "#     # Disable training for the generator\n",
        "#     combined_model.layers[0].trainable = False\n",
        "#     combined_model.layers[1].trainable = True\n"
      ],
      "metadata": {
        "id": "22E3L4-JMnFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained VGG16 model (excluding the top layer)\n",
        "inc_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# # Freeze the base model layers\n",
        "# for layer in inc_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# Create your CNN model based on VGG16\n",
        "model = Sequential()\n",
        "model.add(vgg_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(43, activation='softmax'))  # 43 is the number of classes in this example\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the generator\n",
        "training_history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "        epochs=6,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl3kYcyqJdQJ",
        "outputId": "8f0dd74a-c255-4f5b-a29f-88b7d1534132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "821/980 [========================>.....] - ETA: 1:41 - loss: 3.5227 - accuracy: 0.0543"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = '/content/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        classes=['test_partial'],\n",
        "        target_size=image_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "probabilities = model.predict(test_generator)\n",
        "\n",
        "# Load the ground truth labels from the CSV file\n",
        "test_labels = pd.read_csv('test_classes_partial.csv')\n",
        "\n",
        "# Get the predicted labels from the model\n",
        "predicted_labels = [np.argmax(probas) for probas in probabilities]\n",
        "\n",
        "# Get the true labels from the ground truth\n",
        "true_labels = test_labels['ClassId'].to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4H7ritGJdLI",
        "outputId": "4a99fd4d-4cad-46a6-ba20-82aed3f2f285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 201 images belonging to 1 classes.\n",
            "7/7 [==============================] - 3s 401ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1 Score:', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJpkAsxNJdDZ",
        "outputId": "5a00989d-1f34-4bd2-862f-23683ca91ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.03980099502487562\n",
            "Precision: 0.001584119204970174\n",
            "Recall: 0.03980099502487562\n",
            "F1 Score: 0.0030469661263062674\n"
          ]
        }
      ]
    }
  ]
}